{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stockprediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4/73l6C6C0oiniO0X/YZc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alteregoxiv/stockpred/blob/main/stockprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgd1YiGWppPz"
      },
      "source": [
        "# **STOCK PREDICTION USING LSTM(KERAS)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev5-W2HvWUpB"
      },
      "source": [
        "# **Importing necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT7zcAoIcksy"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnVYQZhNWcKe"
      },
      "source": [
        "# **Training Data Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zxg_MYh3SOAk",
        "outputId": "641d75aa-e745-4013-cfd5-8da47f17e2e0"
      },
      "source": [
        "traindata = pd.read_csv(\"./AMZNtrain.csv\")\n",
        "traindata.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>398.799988</td>\n",
              "      <td>399.359985</td>\n",
              "      <td>394.019989</td>\n",
              "      <td>397.970001</td>\n",
              "      <td>397.970001</td>\n",
              "      <td>2137800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>398.290009</td>\n",
              "      <td>402.709991</td>\n",
              "      <td>396.220001</td>\n",
              "      <td>396.440002</td>\n",
              "      <td>396.440002</td>\n",
              "      <td>2210200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014-01-06</td>\n",
              "      <td>395.850006</td>\n",
              "      <td>397.000000</td>\n",
              "      <td>388.420013</td>\n",
              "      <td>393.630005</td>\n",
              "      <td>393.630005</td>\n",
              "      <td>3170600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-01-07</td>\n",
              "      <td>395.040009</td>\n",
              "      <td>398.470001</td>\n",
              "      <td>394.290009</td>\n",
              "      <td>398.029999</td>\n",
              "      <td>398.029999</td>\n",
              "      <td>1916000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014-01-08</td>\n",
              "      <td>398.470001</td>\n",
              "      <td>403.000000</td>\n",
              "      <td>396.040009</td>\n",
              "      <td>401.920013</td>\n",
              "      <td>401.920013</td>\n",
              "      <td>2316500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date        Open        High  ...       Close   Adj Close   Volume\n",
              "0  2014-01-02  398.799988  399.359985  ...  397.970001  397.970001  2137800\n",
              "1  2014-01-03  398.290009  402.709991  ...  396.440002  396.440002  2210200\n",
              "2  2014-01-06  395.850006  397.000000  ...  393.630005  393.630005  3170600\n",
              "3  2014-01-07  395.040009  398.470001  ...  398.029999  398.029999  1916000\n",
              "4  2014-01-08  398.470001  403.000000  ...  401.920013  401.920013  2316500\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPEpZlynWnQW"
      },
      "source": [
        "# **Testing Data Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JVYD_bNkSg5d",
        "outputId": "42153a45-d44e-4973-f367-5495fba6df09"
      },
      "source": [
        "testdata = pd.read_csv(\"./AMZNtest.csv\")\n",
        "testdata.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>1465.199951</td>\n",
              "      <td>1553.359985</td>\n",
              "      <td>1460.930054</td>\n",
              "      <td>1539.130005</td>\n",
              "      <td>1539.130005</td>\n",
              "      <td>7983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>1520.010010</td>\n",
              "      <td>1538.000000</td>\n",
              "      <td>1497.109985</td>\n",
              "      <td>1500.280029</td>\n",
              "      <td>1500.280029</td>\n",
              "      <td>6975600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>1530.000000</td>\n",
              "      <td>1594.000000</td>\n",
              "      <td>1518.310059</td>\n",
              "      <td>1575.390015</td>\n",
              "      <td>1575.390015</td>\n",
              "      <td>9182600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-07</td>\n",
              "      <td>1602.310059</td>\n",
              "      <td>1634.560059</td>\n",
              "      <td>1589.189941</td>\n",
              "      <td>1629.510010</td>\n",
              "      <td>1629.510010</td>\n",
              "      <td>7993200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-08</td>\n",
              "      <td>1664.689941</td>\n",
              "      <td>1676.609985</td>\n",
              "      <td>1616.609985</td>\n",
              "      <td>1656.579956</td>\n",
              "      <td>1656.579956</td>\n",
              "      <td>8881400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date         Open         High  ...        Close    Adj Close   Volume\n",
              "0  2019-01-02  1465.199951  1553.359985  ...  1539.130005  1539.130005  7983100\n",
              "1  2019-01-03  1520.010010  1538.000000  ...  1500.280029  1500.280029  6975600\n",
              "2  2019-01-04  1530.000000  1594.000000  ...  1575.390015  1575.390015  9182600\n",
              "3  2019-01-07  1602.310059  1634.560059  ...  1629.510010  1629.510010  7993200\n",
              "4  2019-01-08  1664.689941  1676.609985  ...  1656.579956  1656.579956  8881400\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URHQm4XdWrNU"
      },
      "source": [
        "# **Shapes of both data sets(Train , Test)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF6nBNrZU7Ux",
        "outputId": "64e33f3d-34db-4f09-f096-b34d8dabb19a"
      },
      "source": [
        "traindata.shape , testdata.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1258, 7), (21, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YZOISlTXUqo"
      },
      "source": [
        "# **Concatenating Datasers and Sorting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMCJ0YqEVVlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e095085f-fc72-49a7-bc9f-74a5b7b9b4bb"
      },
      "source": [
        "data = pd.concat([traindata , testdata] , axis=0 , ignore_index=True)\n",
        "data.head"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of             Date         Open         High  ...        Close    Adj Close    Volume\n",
              "0     2014-01-02   398.799988   399.359985  ...   397.970001   397.970001   2137800\n",
              "1     2014-01-03   398.290009   402.709991  ...   396.440002   396.440002   2210200\n",
              "2     2014-01-06   395.850006   397.000000  ...   393.630005   393.630005   3170600\n",
              "3     2014-01-07   395.040009   398.470001  ...   398.029999   398.029999   1916000\n",
              "4     2014-01-08   398.470001   403.000000  ...   401.920013   401.920013   2316500\n",
              "...          ...          ...          ...  ...          ...          ...       ...\n",
              "1274  2019-01-25  1670.500000  1683.479980  ...  1670.569946  1670.569946   4945900\n",
              "1275  2019-01-28  1643.589966  1645.000000  ...  1637.890015  1637.890015   4837700\n",
              "1276  2019-01-29  1631.270020  1632.380005  ...  1593.880005  1593.880005   4632800\n",
              "1277  2019-01-30  1623.000000  1676.949951  ...  1670.430054  1670.430054   5783800\n",
              "1278  2019-01-31  1692.849976  1736.410034  ...  1718.729980  1718.729980  10910300\n",
              "\n",
              "[1279 rows x 7 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "SEFBWlNzXazd",
        "outputId": "7da8b5bf-0426-4772-fdc5-68d5ea0ec3d5"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  date = data[\"Date\"][i]\n",
        "  d = date.split(\"-\")\n",
        "  s = str(d[0]) + str(d[1]) + str(d[2])\n",
        "  data[\"Date\"][i] = s\n",
        "data.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20140102</td>\n",
              "      <td>398.799988</td>\n",
              "      <td>399.359985</td>\n",
              "      <td>394.019989</td>\n",
              "      <td>397.970001</td>\n",
              "      <td>397.970001</td>\n",
              "      <td>2137800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20140103</td>\n",
              "      <td>398.290009</td>\n",
              "      <td>402.709991</td>\n",
              "      <td>396.220001</td>\n",
              "      <td>396.440002</td>\n",
              "      <td>396.440002</td>\n",
              "      <td>2210200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20140106</td>\n",
              "      <td>395.850006</td>\n",
              "      <td>397.000000</td>\n",
              "      <td>388.420013</td>\n",
              "      <td>393.630005</td>\n",
              "      <td>393.630005</td>\n",
              "      <td>3170600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20140107</td>\n",
              "      <td>395.040009</td>\n",
              "      <td>398.470001</td>\n",
              "      <td>394.290009</td>\n",
              "      <td>398.029999</td>\n",
              "      <td>398.029999</td>\n",
              "      <td>1916000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20140108</td>\n",
              "      <td>398.470001</td>\n",
              "      <td>403.000000</td>\n",
              "      <td>396.040009</td>\n",
              "      <td>401.920013</td>\n",
              "      <td>401.920013</td>\n",
              "      <td>2316500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date        Open        High  ...       Close   Adj Close   Volume\n",
              "0  20140102  398.799988  399.359985  ...  397.970001  397.970001  2137800\n",
              "1  20140103  398.290009  402.709991  ...  396.440002  396.440002  2210200\n",
              "2  20140106  395.850006  397.000000  ...  393.630005  393.630005  3170600\n",
              "3  20140107  395.040009  398.470001  ...  398.029999  398.029999  1916000\n",
              "4  20140108  398.470001  403.000000  ...  401.920013  401.920013  2316500\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl95h11OhUXG",
        "outputId": "ef3d192b-bc90-4b44-af76-d90537215685"
      },
      "source": [
        "data = data.sort_index(ascending=True , axis=0)\n",
        "data.head"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of           Date         Open         High  ...        Close    Adj Close    Volume\n",
              "0     20140102   398.799988   399.359985  ...   397.970001   397.970001   2137800\n",
              "1     20140103   398.290009   402.709991  ...   396.440002   396.440002   2210200\n",
              "2     20140106   395.850006   397.000000  ...   393.630005   393.630005   3170600\n",
              "3     20140107   395.040009   398.470001  ...   398.029999   398.029999   1916000\n",
              "4     20140108   398.470001   403.000000  ...   401.920013   401.920013   2316500\n",
              "...        ...          ...          ...  ...          ...          ...       ...\n",
              "1274  20190125  1670.500000  1683.479980  ...  1670.569946  1670.569946   4945900\n",
              "1275  20190128  1643.589966  1645.000000  ...  1637.890015  1637.890015   4837700\n",
              "1276  20190129  1631.270020  1632.380005  ...  1593.880005  1593.880005   4632800\n",
              "1277  20190130  1623.000000  1676.949951  ...  1670.430054  1670.430054   5783800\n",
              "1278  20190131  1692.849976  1736.410034  ...  1718.729980  1718.729980  10910300\n",
              "\n",
              "[1279 rows x 7 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmL2H46GhxzR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFvm1e-Vnsvt"
      },
      "source": [
        "# **Saving the DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBruMR6WhxB7"
      },
      "source": [
        "data.to_csv(r'./AMZNTotalData.csv' , index=False)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvQ5cI7ykyvr",
        "outputId": "a6392ab0-b5f8-496b-c588-c802994b2970"
      },
      "source": [
        "newdata = pd.read_csv(\"./AMZNTotalData.csv\")\n",
        "newdata.head"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of           Date         Open         High  ...        Close    Adj Close    Volume\n",
              "0     20140102   398.799988   399.359985  ...   397.970001   397.970001   2137800\n",
              "1     20140103   398.290009   402.709991  ...   396.440002   396.440002   2210200\n",
              "2     20140106   395.850006   397.000000  ...   393.630005   393.630005   3170600\n",
              "3     20140107   395.040009   398.470001  ...   398.029999   398.029999   1916000\n",
              "4     20140108   398.470001   403.000000  ...   401.920013   401.920013   2316500\n",
              "...        ...          ...          ...  ...          ...          ...       ...\n",
              "1274  20190125  1670.500000  1683.479980  ...  1670.569946  1670.569946   4945900\n",
              "1275  20190128  1643.589966  1645.000000  ...  1637.890015  1637.890015   4837700\n",
              "1276  20190129  1631.270020  1632.380005  ...  1593.880005  1593.880005   4632800\n",
              "1277  20190130  1623.000000  1676.949951  ...  1670.430054  1670.430054   5783800\n",
              "1278  20190131  1692.849976  1736.410034  ...  1718.729980  1718.729980  10910300\n",
              "\n",
              "[1279 rows x 7 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37LGB3wEp93X"
      },
      "source": [
        "# **Test Train Split from the concatenated Data Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZnXpPuIonv9",
        "outputId": "2dbc7ac1-250e-40a3-898c-f1424855d1b8"
      },
      "source": [
        "limit = np.random.rand((len(newdata)))<0.7\n",
        "train = newdata[limit]\n",
        "test = newdata[~limit]\n",
        "train.shape , test.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((890, 7), (389, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXTXV-D4qQot",
        "outputId": "2cdf85ef-360d-4d3f-fb5c-669f0aa2a82a"
      },
      "source": [
        "newtrain = train[['Adj Close']]\n",
        "newtest = test[['Adj Close']]\n",
        "\n",
        "newtrain.shape , newtest.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((890, 1), (389, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD7YgMi7yU3g"
      },
      "source": [
        "# **Scaling the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5e02dL5-PoF"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "\n",
        "newtrain = sc.fit_transform(newtrain)\n",
        "newtest = sc.fit_transform(newtest)\n",
        "\n",
        "newtrain = np.reshape(newtrain , (-1 , 1))\n",
        "newtest = np.reshape(newtest , (-1 , 1))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N84K9DW2yepY"
      },
      "source": [
        "# **Preparing the Final data using timestep for LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAixTgSxeNNF"
      },
      "source": [
        "def final_data(data , timestep):\n",
        "  xdata , ydata = [] , []\n",
        "  l = len(data)\n",
        "  for i in range(l-timestep):\n",
        "    a = data[i : i+timestep , 0]\n",
        "    xdata.append(a)\n",
        "    ydata.append(data[i+timestep , 0])\n",
        "  return np.array(xdata) , np.array(ydata)\n",
        "\n",
        "\n",
        "\n",
        "timestep = 60\n",
        "xtrain  , ytrain = final_data(newtrain , timestep)\n",
        "xtest , ytest = final_data(newtest , timestep)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA1JwMQYh5GZ"
      },
      "source": [
        "xtrain = xtrain.reshape(xtrain.shape[0] , xtrain.shape[1] , 1)\n",
        "xtest = xtest.reshape(xtest.shape[0] , xtest.shape[1] , 1)\n",
        "#xtrain.shape\n",
        "#print(xtrain)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G-BglZkzh6V"
      },
      "source": [
        "# **Preparing Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC_0T-jFjw6E"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , LSTM"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra1u6nyUkkVV"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50 , return_sequences=True , input_shape=(60 , 1)))\n",
        "model.add(LSTM(50 , return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error' , optimizer='adam')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWzEihXDnLmu",
        "outputId": "c92a00b4-15c2-423a-851f-7c5323a6f62c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 60, 50)            10400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 60, 50)            20200     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 50,851\n",
            "Trainable params: 50,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GUCkn8pzmYy"
      },
      "source": [
        "# **Fitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IESruTGgnRog",
        "outputId": "ec1d277d-c480-4fe1-c409-74a996b81676"
      },
      "source": [
        "model.fit(xtrain , ytrain , validation_data=(xtest , ytest) , epochs=100 , batch_size=64 , verbose=1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 8s 213ms/step - loss: 0.0580 - val_loss: 0.0111\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.0073 - val_loss: 0.0041\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.0019 - val_loss: 0.0026\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 0.0012 - val_loss: 0.0028\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.0011 - val_loss: 0.0028\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.0011 - val_loss: 0.0023\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.0011 - val_loss: 0.0023\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.0010 - val_loss: 0.0022\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.0011 - val_loss: 0.0023\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.0010 - val_loss: 0.0022\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 9.9186e-04 - val_loss: 0.0022\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 9.7570e-04 - val_loss: 0.0021\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.0010 - val_loss: 0.0021\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.0010 - val_loss: 0.0021\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 9.0052e-04 - val_loss: 0.0023\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 116ms/step - loss: 9.3224e-04 - val_loss: 0.0020\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 8.6374e-04 - val_loss: 0.0020\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 8.1830e-04 - val_loss: 0.0021\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 8.4079e-04 - val_loss: 0.0018\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 9.0879e-04 - val_loss: 0.0020\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 8.3319e-04 - val_loss: 0.0018\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 7.8783e-04 - val_loss: 0.0018\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 8.2878e-04 - val_loss: 0.0021\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 8.5510e-04 - val_loss: 0.0019\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 8.4548e-04 - val_loss: 0.0018\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 7.7578e-04 - val_loss: 0.0018\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 8.3121e-04 - val_loss: 0.0018\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 8.1955e-04 - val_loss: 0.0017\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 7.5995e-04 - val_loss: 0.0024\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 9.7977e-04 - val_loss: 0.0021\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 9.5671e-04 - val_loss: 0.0017\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 9.4124e-04 - val_loss: 0.0017\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 7.2348e-04 - val_loss: 0.0018\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 7.1526e-04 - val_loss: 0.0016\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 7.5615e-04 - val_loss: 0.0016\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 7.1785e-04 - val_loss: 0.0016\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 7.9499e-04 - val_loss: 0.0019\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 8.2524e-04 - val_loss: 0.0019\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 6.9133e-04 - val_loss: 0.0016\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 7.1915e-04 - val_loss: 0.0015\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 7.4294e-04 - val_loss: 0.0015\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 7.5404e-04 - val_loss: 0.0016\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 7.9647e-04 - val_loss: 0.0015\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 6.5532e-04 - val_loss: 0.0019\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 7.1671e-04 - val_loss: 0.0016\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 7.2025e-04 - val_loss: 0.0015\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 6.9573e-04 - val_loss: 0.0015\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 7.6655e-04 - val_loss: 0.0015\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 8.5477e-04 - val_loss: 0.0016\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 8.1143e-04 - val_loss: 0.0013\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 6.6084e-04 - val_loss: 0.0013\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 6.6924e-04 - val_loss: 0.0013\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 6.6113e-04 - val_loss: 0.0012\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 7.5680e-04 - val_loss: 0.0014\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 6.7140e-04 - val_loss: 0.0013\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 6.1958e-04 - val_loss: 0.0013\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 6.1512e-04 - val_loss: 0.0013\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 6.0120e-04 - val_loss: 0.0011\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 6.0229e-04 - val_loss: 0.0011\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 5.8709e-04 - val_loss: 0.0012\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 6.2381e-04 - val_loss: 0.0016\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 6.2044e-04 - val_loss: 0.0013\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 6.3343e-04 - val_loss: 0.0011\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 5.7393e-04 - val_loss: 0.0010\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 5.6721e-04 - val_loss: 9.7071e-04\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 6.4238e-04 - val_loss: 0.0014\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 5.8445e-04 - val_loss: 9.9247e-04\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 5.3800e-04 - val_loss: 0.0011\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 6.1875e-04 - val_loss: 8.9030e-04\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 5.0868e-04 - val_loss: 9.1258e-04\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 4.8865e-04 - val_loss: 0.0010\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 5.3089e-04 - val_loss: 0.0011\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 4.8782e-04 - val_loss: 9.1501e-04\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 4.5653e-04 - val_loss: 0.0010\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 4.9139e-04 - val_loss: 7.9711e-04\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 4.4027e-04 - val_loss: 8.7098e-04\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 5.3283e-04 - val_loss: 0.0012\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 4.7209e-04 - val_loss: 8.3585e-04\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 4.0608e-04 - val_loss: 7.6173e-04\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 4.6376e-04 - val_loss: 8.2813e-04\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 4.4058e-04 - val_loss: 9.0284e-04\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 4.6008e-04 - val_loss: 0.0010\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 4.4545e-04 - val_loss: 7.7289e-04\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 4.0607e-04 - val_loss: 7.1711e-04\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 3.4256e-04 - val_loss: 7.3552e-04\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 3.5464e-04 - val_loss: 7.5658e-04\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 3.4444e-04 - val_loss: 6.7935e-04\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 3.7613e-04 - val_loss: 7.5788e-04\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 3.8419e-04 - val_loss: 8.3244e-04\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 3.5263e-04 - val_loss: 8.4092e-04\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 4.1472e-04 - val_loss: 7.6348e-04\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 3.5013e-04 - val_loss: 6.5704e-04\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 3.3624e-04 - val_loss: 6.7999e-04\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 3.1397e-04 - val_loss: 7.2636e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0499cf3810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    }
  ]
}